{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated UST_BOND_FU_weekly with new data.\n",
      "Updated UST_BOND_FO_weekly with new data.\n",
      "Updated UST_ULTRA_BOND_FU_weekly with new data.\n",
      "Updated UST_ULTRA_BOND_FO_weekly with new data.\n",
      "Updated UST_2Y_FU_weekly with new data.\n",
      "Updated UST_2Y_FO_weekly with new data.\n",
      "Updated UST_10Y_FU_weekly with new data.\n",
      "Updated UST_10Y_FO_weekly with new data.\n",
      "Updated UST_ULTRA_10Y_FU_weekly with new data.\n",
      "Updated UST_ULTRA_10Y_FO_weekly with new data.\n",
      "Updated UST_5Y_FU_weekly with new data.\n",
      "Updated UST_5Y_FO_weekly with new data.\n",
      "Updated SP500_eMini_FU_weekly with new data.\n",
      "Updated SP500_eMini_FO_weekly with new data.\n",
      "Updated RUSSELL_eMini_FU_weekly with new data.\n",
      "Updated RUSSELL_eMini_FO_weekly with new data.\n",
      "Updated EURO_FU_weekly with new data.\n",
      "Updated EURO_FO_weekly with new data.\n",
      "Updated YEN_FU_weekly with new data.\n",
      "Updated YEN_FO_weekly with new data.\n",
      "Updated GBP_FU_weekly with new data.\n",
      "Updated GBP_FO_weekly with new data.\n",
      "Updated WTI_PHYS_FU_weekly with new data.\n",
      "Updated WTI_PHYS_FO_weekly with new data.\n",
      "Updated WTI_FIN_FU_weekly with new data.\n",
      "Updated WTI_FIN_FO_weekly with new data.\n",
      "Updated PESO_FU_weekly with new data.\n",
      "Updated PESO_FO_weekly with new data.\n",
      "Updated CAD_FU_weekly with new data.\n",
      "Updated CAD_FO_weekly with new data.\n",
      "Updated COPPER_FU_weekly with new data.\n",
      "Updated COPPER_FO_weekly with new data.\n",
      "Updated NATGAS_FO_weekly with new data.\n",
      "Updated CHF_FU_weekly with new data.\n",
      "Updated CHF_FO_weekly with new data.\n",
      "Updated AUD_FU_weekly with new data.\n",
      "Updated AUD_FO_weekly with new data.\n",
      "Database updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import quandl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Set your Quandl API key\n",
    "quandl.ApiConfig.api_key = 'FMezMmR86K7axszB_rkz'\n",
    "\n",
    "# Create an SQLite connection and cursor\n",
    "conn = sqlite3.connect('CoT_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the new series codes\n",
    "series_codes = {\n",
    "    \"020601_F_ALL\":'UST_BOND_FU', \"020601_FO_ALL\":'UST_BOND_FO',\n",
    "    \"020604_F_ALL\":'UST_ULTRA_BOND_FU', \"020604_FO_ALL\":'UST_ULTRA_BOND_FO',\n",
    "    \"042601_F_ALL\":'UST_2Y_FU', \"042601_FO_ALL\":'UST_2Y_FO',\n",
    "    \"043602_F_ALL\":'UST_10Y_FU', \"043602_FO_ALL\":'UST_10Y_FO',\n",
    "    \"043607_F_ALL\":'UST_ULTRA_10Y_FU', \"043607_FO_ALL\":'UST_ULTRA_10Y_FO',\n",
    "    \"044601_F_ALL\":'UST_5Y_FU', \"044601_FO_ALL\":'UST_5Y_FO',\n",
    "    \"13874A_F_ALL\":'SP500_eMini_FU',\"13874A_FO_ALL\":'SP500_eMini_FO',\n",
    "    \"239742_F_ALL\":'RUSSELL_eMini_FU',\"239742_FO_ALL\":'RUSSELL_eMini_FO',\n",
    "    \"099741_F_L_ALL\":'EURO_FU',\"099741_FO_L_ALL\":'EURO_FO', \n",
    "    \"097741_F_L_ALL\": 'YEN_FU',\"097741_FO_L_ALL\":'YEN_FO',\n",
    "    \"096742_F_L_ALL\":'GBP_FU',\"096742_FO_L_ALL\":'GBP_FO',\n",
    "    \"067651_F_L_ALL\":'WTI_PHYS_FU',\"067651_FO_L_ALL\":'WTI_PHYS_FO',\n",
    "    \"06765A_F_ALL\":\"WTI_FIN_FU\",\"06765A_FO_ALL\":'WTI_FIN_FO',\n",
    "    \"095741_F_L_ALL\":'PESO_FU',\"095741_FO_L_ALL\":'PESO_FO',\n",
    "    \"090741_F_L_ALL\":'CAD_FU',\"090741_FO_L_ALL\":'CAD_FO',\n",
    "    \"085692_F_L_ALL\":'COPPER_FU',\"085692_FO_L_ALL\":'COPPER_FO',\n",
    "    \"023651_F_L_ALL\":'NATGAS_FU',\"023651_F_L_ALL\":'NATGAS_FO',\n",
    "    \"092741_F_L_ALL\":'CHF_FU',\"092741_FO_L_ALL\":'CHF_FO',\n",
    "    \"232741_F_L_ALL\":'AUD_FU',\"232741_FO_L_ALL\":'AUD_FO'}\n",
    "\n",
    "# Prefix to be added to each series code\n",
    "prefix = \"CFTC/\"\n",
    "\n",
    "# Function to update a table with new data\n",
    "def update_table(series_code, periodicity):\n",
    "    full_series_code = prefix + series_code\n",
    "    table_name = series_codes[series_code] + '_' + periodicity\n",
    "    # Print the list of existing tables\n",
    "    existing_tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    existing_tables = cursor.execute(existing_tables_query).fetchall()\n",
    "    # print(\"Existing Tables:\", [table[0] for table in existing_tables])\n",
    "\n",
    "    # Check the latest date in the existing table\n",
    "    query_latest_date = f'SELECT MAX(Date) FROM \"{table_name}\"'  # Use double quotes for table name\n",
    "    latest_date = pd.read_sql_query(query_latest_date, conn).iloc[0, 0]\n",
    "\n",
    "    query_third_latest_date =  f'SELECT Date FROM \"{table_name}\" ORDER BY Date DESC;'\n",
    "    third_to_last_date = pd.read_sql_query(query_third_latest_date, conn).loc[2] # zero indexed\n",
    "\n",
    "    # Fetch existing data from the database\n",
    "    existing_data_query = f'SELECT * FROM \"{table_name}\"'\n",
    "    existing_data = pd.read_sql_query(existing_data_query, conn)\n",
    "    # Ensure numeric data types in existing data\n",
    "    existing_data_numeric = existing_data.apply(pd.to_numeric, errors='coerce')\n",
    "    existing_data_numeric = existing_data_numeric.dropna()\n",
    "  \n",
    "    # Fetch new data from Quandl if available\n",
    "    new_data = quandl.get(full_series_code, collapse=periodicity, start_date=third_to_last_date)\n",
    "\n",
    "    if not new_data.empty:\n",
    "        # Safety checks\n",
    "        if new_data.isnull().values.any():\n",
    "            print(f\"Warning: Missing values found in {table_name}. Skipping update.\")\n",
    "            return\n",
    "\n",
    "        expected_data_types = [np.float64]\n",
    "        if not all(pd.api.types.is_numeric_dtype(dtype) for dtype in new_data.dtypes):\n",
    "            print(f\"Warning: Incorrect data types found in {table_name}.\")\n",
    "            print(f\"Expected data types: {expected_data_types}\")\n",
    "            print(f\"Actual data types: {new_data.dtypes}\")\n",
    "            print(\"Proceeding with the update.\")\n",
    "\n",
    "        # Calculate IQR from existing data\n",
    "        Q1_existing = existing_data_numeric.quantile(0.25)\n",
    "        Q3_existing = existing_data_numeric.quantile(0.75)\n",
    "        IQR_existing = Q3_existing - Q1_existing\n",
    "\n",
    "        # Get the intersection of columns\n",
    "        common_columns = new_data.columns.intersection(existing_data_numeric.columns)\n",
    "\n",
    "        # Identify outliers using the IQR method on common columns\n",
    "        outliers = (\n",
    "            (new_data[common_columns] < (Q1_existing[common_columns] - 1.5 * IQR_existing[common_columns])) |\n",
    "            (new_data[common_columns] > (Q3_existing[common_columns] + 1.5 * IQR_existing[common_columns]))\n",
    "        ).any(axis=1)\n",
    "        if outliers.any():\n",
    "            warnings.warn(f\"Warning: Outliers found in {table_name}. Proceeding with the update.\")\n",
    "\n",
    "        # Check for duplicate date observations\n",
    "        if latest_date is not None and new_data.index.max() <= pd.to_datetime(latest_date):\n",
    "            print(f\"No new data available for {table_name}.\")\n",
    "        else:\n",
    "            # Append new observations to the original table\n",
    "            new_observations = new_data[new_data.index > pd.to_datetime(latest_date)]\n",
    "            new_observations.to_sql(table_name, conn, if_exists='append', index=True)\n",
    "            # Create a table for the period-to-period difference\n",
    "            diff_data = new_data.diff().dropna()\n",
    "            new_observations = diff_data[diff_data.index > pd.to_datetime(latest_date)]\n",
    "            diff_table_name = table_name + '_diff'\n",
    "            new_observations.to_sql(diff_table_name, conn, if_exists='append', index=True)\n",
    "\n",
    "            # Create a table for the percent change with handling of Inf values\n",
    "            percent_change_data = new_data.pct_change().dropna()\n",
    "            new_observations = percent_change_data[percent_change_data.index > pd.to_datetime(latest_date)]\n",
    "            percent_change_table_name = table_name + '_percent_change'\n",
    "            new_observations.to_sql(percent_change_table_name, conn, if_exists='append', index=True)\n",
    "\n",
    "            print(f\"Updated {table_name} with new data.\")\n",
    "    else:\n",
    "        print(f\"No new data available for {table_name}.\")\n",
    "\n",
    "\n",
    "periodicities = {'weekly'}\n",
    "# Update tables for each series code\n",
    "for series_code in series_codes:\n",
    "    for periodicity in periodicities:\n",
    "        update_table(series_code, periodicity)\n",
    "        \n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Database updated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
