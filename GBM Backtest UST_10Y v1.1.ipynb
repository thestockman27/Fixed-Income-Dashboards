{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/dstoc/Documents/Python Scripts/Fixed Income Dashboards/reduced_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# Assuming 'Date' is the name of the column containing date information\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.set_index('Date', inplace=True)\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna(axis = 1)\n",
    "\n",
    "# Define the features (independent variables) and target (dependent variable)\n",
    "features = list(df2)\n",
    "# Define the lag order (number of lags to create)\n",
    "lag_order = 6  # Example: Creating lagged values for the past n periods\n",
    "# Define the initial training size (e.g., 70% of the data)\n",
    "initial_train_size = int(0.7 * len(df2)) - lag_order\n",
    "InSamp_length = len(df2) - initial_train_size - lag_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of periods to lead the target variable (1 period in this case)\n",
    "lead_periods = 1\n",
    "\n",
    "# redefine the features (independent variables) and target (dependent variable)\n",
    "features = list(df2)\n",
    "\n",
    "# Create a new variable representing the 'lead' of the target\n",
    "df2['YIELD_weekly_percent_change_10 YR_lead'] = df2['YIELD_weekly_percent_change_10 YR'].shift(-lead_periods)\n",
    "\n",
    "# Drop rows with missing values in the features or target (created by the shift)\n",
    "df2 = df2.dropna(subset=features + ['YIELD_weekly_percent_change_10 YR_lead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-10-22    0.064795\n",
       "2023-10-29   -0.018256\n",
       "2023-11-05   -0.055785\n",
       "2023-11-12    0.008753\n",
       "2023-11-19   -0.036876\n",
       "Name: YIELD_weekly_percent_change_10 YR, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['YIELD_weekly_percent_change_10 YR'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "features = list(df3.select_dtypes(include=['float64', 'int64']).columns)[0:(len(df3.columns)-1)]\n",
    "X = df3[features]\n",
    "y = df3['YIELD_weekly_percent_change_10 YR_lead']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame X does not contain the target variable: 'YIELD_weekly_percent_change_10 YR_lead'.\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.copy()\n",
    "features = list(df3.columns)[0:(len(df3.columns)-1)]\n",
    "X = df3[features]\n",
    "y = df3['YIELD_weekly_percent_change_10 YR_lead']\n",
    "\n",
    "target_var = 'YIELD_weekly_percent_change_10 YR_lead'\n",
    "\n",
    "if target_var.lower() in map(str.lower, X.columns):\n",
    "    print(f\"The DataFrame contains the column '{target_var}'.\")\n",
    "else:\n",
    "    print(f\"The DataFrame X does not contain the target variable: '{target_var}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman's rank correlation is often used when the variables being compared may not have a linear relationship or when the assumptions of parametric correlation measures like Pearson's correlation are not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YIELD_weekly_percent_change_6 MO</th>\n",
       "      <th>YIELD_weekly_percent_change_1 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_2 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_3 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_5 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_7 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_10 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_20 YR</th>\n",
       "      <th>YIELD_weekly_percent_change_30 YR</th>\n",
       "      <th>UST_BOND_FU_weekly_percent_change_Open Interest</th>\n",
       "      <th>...</th>\n",
       "      <th>AUD_FO_weekly_percent_change_Commercial Short</th>\n",
       "      <th>AUD_FO_weekly_percent_change_Total Long</th>\n",
       "      <th>AUD_FO_weekly_percent_change_Total Short</th>\n",
       "      <th>AUD_FO_weekly_percent_change_Nonreportable Positions Long</th>\n",
       "      <th>AUD_FO_weekly_percent_change_Nonreportable Positions Short</th>\n",
       "      <th>SOMA_weekly_percent_change_tips</th>\n",
       "      <th>SOMA_weekly_percent_change_tipsInflationCompensation</th>\n",
       "      <th>SOMA_weekly_percent_change_notesbonds</th>\n",
       "      <th>SOMA_weekly_percent_change_total</th>\n",
       "      <th>YIELD_weekly_percent_change_10 YR_lead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-08-14</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.346939</td>\n",
       "      <td>-0.219512</td>\n",
       "      <td>-0.183246</td>\n",
       "      <td>-0.131783</td>\n",
       "      <td>-0.071633</td>\n",
       "      <td>-0.026178</td>\n",
       "      <td>-0.004792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301706</td>\n",
       "      <td>-0.196299</td>\n",
       "      <td>-0.269874</td>\n",
       "      <td>-0.189682</td>\n",
       "      <td>0.357707</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>-0.075893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-21</th>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.075893</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.088710</td>\n",
       "      <td>-0.008830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>0.035299</td>\n",
       "      <td>-0.063064</td>\n",
       "      <td>-0.210482</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001934</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>0.057971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-28</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202267</td>\n",
       "      <td>0.089482</td>\n",
       "      <td>0.117490</td>\n",
       "      <td>0.049925</td>\n",
       "      <td>-0.039729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.077626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-04</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.063830</td>\n",
       "      <td>-0.072368</td>\n",
       "      <td>-0.077626</td>\n",
       "      <td>-0.067093</td>\n",
       "      <td>-0.062147</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.055818</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>0.133626</td>\n",
       "      <td>-0.077249</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>-0.001445</td>\n",
       "      <td>-0.044554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>-0.079545</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.044554</td>\n",
       "      <td>-0.020548</td>\n",
       "      <td>-0.018072</td>\n",
       "      <td>-0.067396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083508</td>\n",
       "      <td>0.093430</td>\n",
       "      <td>0.137267</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>-0.118270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.077720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            YIELD_weekly_percent_change_6 MO  \\\n",
       "Date                                           \n",
       "2011-08-14                          0.400000   \n",
       "2011-08-21                         -0.428571   \n",
       "2011-08-28                         -0.500000   \n",
       "2011-09-04                          1.500000   \n",
       "2011-09-11                          0.000000   \n",
       "\n",
       "            YIELD_weekly_percent_change_1 YR  \\\n",
       "Date                                           \n",
       "2011-08-14                          0.000000   \n",
       "2011-08-21                         -0.090909   \n",
       "2011-08-28                         -0.100000   \n",
       "2011-09-04                          0.111111   \n",
       "2011-09-11                          0.100000   \n",
       "\n",
       "            YIELD_weekly_percent_change_2 YR  \\\n",
       "Date                                           \n",
       "2011-08-14                         -0.285714   \n",
       "2011-08-21                          0.000000   \n",
       "2011-08-28                          0.000000   \n",
       "2011-09-04                          0.000000   \n",
       "2011-09-11                         -0.150000   \n",
       "\n",
       "            YIELD_weekly_percent_change_3 YR  \\\n",
       "Date                                           \n",
       "2011-08-14                         -0.346939   \n",
       "2011-08-21                          0.062500   \n",
       "2011-08-28                         -0.029412   \n",
       "2011-09-04                          0.000000   \n",
       "2011-09-11                         -0.060606   \n",
       "\n",
       "            YIELD_weekly_percent_change_5 YR  \\\n",
       "Date                                           \n",
       "2011-08-14                         -0.219512   \n",
       "2011-08-21                         -0.062500   \n",
       "2011-08-28                          0.044444   \n",
       "2011-09-04                         -0.063830   \n",
       "2011-09-11                         -0.079545   \n",
       "\n",
       "            YIELD_weekly_percent_change_7 YR  \\\n",
       "Date                                           \n",
       "2011-08-14                         -0.183246   \n",
       "2011-08-21                         -0.083333   \n",
       "2011-08-28                          0.062937   \n",
       "2011-09-04                         -0.072368   \n",
       "2011-09-11                         -0.049645   \n",
       "\n",
       "            YIELD_weekly_percent_change_10 YR  \\\n",
       "Date                                            \n",
       "2011-08-14                          -0.131783   \n",
       "2011-08-21                          -0.075893   \n",
       "2011-08-28                           0.057971   \n",
       "2011-09-04                          -0.077626   \n",
       "2011-09-11                          -0.044554   \n",
       "\n",
       "            YIELD_weekly_percent_change_20 YR  \\\n",
       "Date                                            \n",
       "2011-08-14                          -0.071633   \n",
       "2011-08-21                          -0.083333   \n",
       "2011-08-28                           0.053872   \n",
       "2011-09-04                          -0.067093   \n",
       "2011-09-11                          -0.020548   \n",
       "\n",
       "            YIELD_weekly_percent_change_30 YR  \\\n",
       "Date                                            \n",
       "2011-08-14                          -0.026178   \n",
       "2011-08-21                          -0.088710   \n",
       "2011-08-28                           0.044248   \n",
       "2011-09-04                          -0.062147   \n",
       "2011-09-11                          -0.018072   \n",
       "\n",
       "            UST_BOND_FU_weekly_percent_change_Open Interest  ...  \\\n",
       "Date                                                         ...   \n",
       "2011-08-14                                        -0.004792  ...   \n",
       "2011-08-21                                        -0.008830  ...   \n",
       "2011-08-28                                         0.021724  ...   \n",
       "2011-09-04                                         0.050251  ...   \n",
       "2011-09-11                                        -0.067396  ...   \n",
       "\n",
       "            AUD_FO_weekly_percent_change_Commercial Short  \\\n",
       "Date                                                        \n",
       "2011-08-14                                      -0.301706   \n",
       "2011-08-21                                      -0.048613   \n",
       "2011-08-28                                       0.202267   \n",
       "2011-09-04                                       0.063076   \n",
       "2011-09-11                                       0.083508   \n",
       "\n",
       "            AUD_FO_weekly_percent_change_Total Long  \\\n",
       "Date                                                  \n",
       "2011-08-14                                -0.196299   \n",
       "2011-08-21                                 0.035299   \n",
       "2011-08-28                                 0.089482   \n",
       "2011-09-04                                 0.055818   \n",
       "2011-09-11                                 0.093430   \n",
       "\n",
       "            AUD_FO_weekly_percent_change_Total Short  \\\n",
       "Date                                                   \n",
       "2011-08-14                                 -0.269874   \n",
       "2011-08-21                                 -0.063064   \n",
       "2011-08-28                                  0.117490   \n",
       "2011-09-04                                  0.110064   \n",
       "2011-09-11                                  0.137267   \n",
       "\n",
       "            AUD_FO_weekly_percent_change_Nonreportable Positions Long  \\\n",
       "Date                                                                    \n",
       "2011-08-14                                          -0.189682           \n",
       "2011-08-21                                          -0.210482           \n",
       "2011-08-28                                           0.049925           \n",
       "2011-09-04                                           0.133626           \n",
       "2011-09-11                                           0.087474           \n",
       "\n",
       "            AUD_FO_weekly_percent_change_Nonreportable Positions Short  \\\n",
       "Date                                                                     \n",
       "2011-08-14                                           0.357707            \n",
       "2011-08-21                                           0.109795            \n",
       "2011-08-28                                          -0.039729            \n",
       "2011-09-04                                          -0.077249            \n",
       "2011-09-11                                          -0.118270            \n",
       "\n",
       "            SOMA_weekly_percent_change_tips  \\\n",
       "Date                                          \n",
       "2011-08-14                         0.006517   \n",
       "2011-08-21                         0.000000   \n",
       "2011-08-28                         0.000000   \n",
       "2011-09-04                         0.012222   \n",
       "2011-09-11                         0.000000   \n",
       "\n",
       "            SOMA_weekly_percent_change_tipsInflationCompensation  \\\n",
       "Date                                                               \n",
       "2011-08-14                                           0.008566      \n",
       "2011-08-21                                          -0.001934      \n",
       "2011-08-28                                          -0.001940      \n",
       "2011-09-04                                           0.009498      \n",
       "2011-09-11                                           0.001656      \n",
       "\n",
       "            SOMA_weekly_percent_change_notesbonds  \\\n",
       "Date                                                \n",
       "2011-08-14                               0.002143   \n",
       "2011-08-21                               0.001876   \n",
       "2011-08-28                               0.000528   \n",
       "2011-09-04                               0.001790   \n",
       "2011-09-11                               0.002228   \n",
       "\n",
       "            SOMA_weekly_percent_change_total  \\\n",
       "Date                                           \n",
       "2011-08-14                          0.001417   \n",
       "2011-08-21                         -0.001354   \n",
       "2011-08-28                         -0.000107   \n",
       "2011-09-04                         -0.001445   \n",
       "2011-09-11                          0.001316   \n",
       "\n",
       "            YIELD_weekly_percent_change_10 YR_lead  \n",
       "Date                                                \n",
       "2011-08-14                               -0.075893  \n",
       "2011-08-21                                0.057971  \n",
       "2011-08-28                               -0.077626  \n",
       "2011-09-04                               -0.044554  \n",
       "2011-09-11                                0.077720  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.iloc[:InSamp_length,].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_top_variables(df, target_variable, num_variables):\n",
    "    # Calculate the rank correlation (Spearman's rho) with the target variable\n",
    "    correlation_matrix = df.corrwith(df[target_variable], method='spearman')\n",
    "    \n",
    "    # Sort variables based on absolute correlation values\n",
    "    sorted_variables = correlation_matrix.abs().sort_values(ascending=False)\n",
    "    \n",
    "    # Select the top variables\n",
    "    selected_variables = sorted_variables.index[:num_variables]\n",
    "    \n",
    "    # Extract the correlation values for the selected variables\n",
    "    selected_correlations = correlation_matrix[selected_variables]\n",
    "    \n",
    "    # Create a DataFrame to store the results\n",
    "    corr_data = pd.DataFrame({\n",
    "        'Variable': selected_variables,\n",
    "        'Correlation': selected_correlations\n",
    "    })\n",
    "    \n",
    "    return corr_data\n",
    "\n",
    "# Assuming df3 is your DataFrame and 'YIELD_weekly_percent_change_10 YR' is the target variable\n",
    "correlated_variables = select_top_variables(df3.loc[df3.index[:InSamp_length]], 'YIELD_weekly_percent_change_10 YR_lead', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YIELD_weekly_percent_change_10 YR_lead</th>\n",
       "      <th>UST_10Y_FO_weekly_percent_change_Non Reportable Shorts</th>\n",
       "      <th>UST_10Y_FU_weekly_percent_change_Non Reportable Longs</th>\n",
       "      <th>UST_10Y_FU_weekly_percent_change_Non Reportable Shorts</th>\n",
       "      <th>UST_10Y_FO_weekly_percent_change_Non Reportable Longs</th>\n",
       "      <th>NATGAS_FO_weekly_percent_change_Noncommercial Long</th>\n",
       "      <th>YEN_FU_weekly_percent_change_Nonreportable Positions Short</th>\n",
       "      <th>UST_10Y_FU_weekly_percent_change_Open Interest</th>\n",
       "      <th>YEN_FO_weekly_percent_change_Nonreportable Positions Short</th>\n",
       "      <th>UST_10Y_FO_weekly_percent_change_Asset Manager Longs</th>\n",
       "      <th>...</th>\n",
       "      <th>YEN_FO_weekly_percent_change_Nonreportable Positions Long</th>\n",
       "      <th>CHF_FO_weekly_percent_change_Open Interest</th>\n",
       "      <th>UST_10Y_FO_weekly_percent_change_Dealer Shorts</th>\n",
       "      <th>SP500_eMini_FU_weekly_percent_change_Other Reportable Longs</th>\n",
       "      <th>PESO_FU_weekly_percent_change_Nonreportable Positions Short</th>\n",
       "      <th>CAD_FU_weekly_percent_change_Open Interest</th>\n",
       "      <th>WTI_PHYS_FO_weekly_percent_change_Noncommercial Long</th>\n",
       "      <th>UST_2Y_FU_weekly_percent_change_Asset Manager Longs</th>\n",
       "      <th>UST_2Y_FU_weekly_percent_change_Dealer Longs</th>\n",
       "      <th>CHF_FO_weekly_percent_change_Nonreportable Positions Long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-06-25</th>\n",
       "      <td>-0.015296</td>\n",
       "      <td>0.075506</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.039968</td>\n",
       "      <td>0.045921</td>\n",
       "      <td>-0.087035</td>\n",
       "      <td>-0.284957</td>\n",
       "      <td>0.096635</td>\n",
       "      <td>-0.277764</td>\n",
       "      <td>0.186905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267675</td>\n",
       "      <td>-0.530200</td>\n",
       "      <td>-0.177814</td>\n",
       "      <td>0.646770</td>\n",
       "      <td>-0.053279</td>\n",
       "      <td>-0.048270</td>\n",
       "      <td>-0.057170</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.185829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-02</th>\n",
       "      <td>-0.001942</td>\n",
       "      <td>-0.053162</td>\n",
       "      <td>-0.031766</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>-0.068202</td>\n",
       "      <td>0.067602</td>\n",
       "      <td>0.098720</td>\n",
       "      <td>0.046394</td>\n",
       "      <td>0.084128</td>\n",
       "      <td>0.061635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.257053</td>\n",
       "      <td>-0.058857</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>-0.272629</td>\n",
       "      <td>0.077938</td>\n",
       "      <td>-0.014777</td>\n",
       "      <td>-0.007761</td>\n",
       "      <td>0.004747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-09</th>\n",
       "      <td>-0.013619</td>\n",
       "      <td>-0.002422</td>\n",
       "      <td>-0.049494</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>-0.049233</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>-0.108938</td>\n",
       "      <td>-0.026388</td>\n",
       "      <td>-0.095245</td>\n",
       "      <td>-0.015988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.072931</td>\n",
       "      <td>-0.055327</td>\n",
       "      <td>-0.203725</td>\n",
       "      <td>-0.130242</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.074313</td>\n",
       "      <td>-0.041798</td>\n",
       "      <td>0.138786</td>\n",
       "      <td>-0.066220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-16</th>\n",
       "      <td>-0.003945</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>-0.018527</td>\n",
       "      <td>0.046073</td>\n",
       "      <td>0.034815</td>\n",
       "      <td>-0.140593</td>\n",
       "      <td>-0.011381</td>\n",
       "      <td>-0.142315</td>\n",
       "      <td>0.055753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019994</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>0.135686</td>\n",
       "      <td>-0.288721</td>\n",
       "      <td>-0.316523</td>\n",
       "      <td>-0.009196</td>\n",
       "      <td>0.076219</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.180686</td>\n",
       "      <td>0.049836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-23</th>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>-0.031302</td>\n",
       "      <td>-0.026084</td>\n",
       "      <td>-0.023064</td>\n",
       "      <td>-0.043627</td>\n",
       "      <td>0.322699</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>0.299812</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053834</td>\n",
       "      <td>0.108912</td>\n",
       "      <td>-0.228154</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>-0.102852</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.145335</td>\n",
       "      <td>-0.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            YIELD_weekly_percent_change_10 YR_lead  \\\n",
       "Date                                                 \n",
       "2006-06-25                               -0.015296   \n",
       "2006-07-02                               -0.001942   \n",
       "2006-07-09                               -0.013619   \n",
       "2006-07-16                               -0.003945   \n",
       "2006-07-23                               -0.009901   \n",
       "\n",
       "            UST_10Y_FO_weekly_percent_change_Non Reportable Shorts  \\\n",
       "Date                                                                 \n",
       "2006-06-25                                           0.075506        \n",
       "2006-07-02                                          -0.053162        \n",
       "2006-07-09                                          -0.002422        \n",
       "2006-07-16                                          -0.022542        \n",
       "2006-07-23                                          -0.001156        \n",
       "\n",
       "            UST_10Y_FU_weekly_percent_change_Non Reportable Longs  \\\n",
       "Date                                                                \n",
       "2006-06-25                                           0.039976       \n",
       "2006-07-02                                          -0.031766       \n",
       "2006-07-09                                          -0.049494       \n",
       "2006-07-16                                           0.034387       \n",
       "2006-07-23                                          -0.031302       \n",
       "\n",
       "            UST_10Y_FU_weekly_percent_change_Non Reportable Shorts  \\\n",
       "Date                                                                 \n",
       "2006-06-25                                           0.039968        \n",
       "2006-07-02                                          -0.012708        \n",
       "2006-07-09                                           0.002832        \n",
       "2006-07-16                                          -0.018527        \n",
       "2006-07-23                                          -0.026084        \n",
       "\n",
       "            UST_10Y_FO_weekly_percent_change_Non Reportable Longs  \\\n",
       "Date                                                                \n",
       "2006-06-25                                           0.045921       \n",
       "2006-07-02                                          -0.068202       \n",
       "2006-07-09                                          -0.049233       \n",
       "2006-07-16                                           0.046073       \n",
       "2006-07-23                                          -0.023064       \n",
       "\n",
       "            NATGAS_FO_weekly_percent_change_Noncommercial Long  \\\n",
       "Date                                                             \n",
       "2006-06-25                                          -0.087035    \n",
       "2006-07-02                                           0.067602    \n",
       "2006-07-09                                           0.014390    \n",
       "2006-07-16                                           0.034815    \n",
       "2006-07-23                                          -0.043627    \n",
       "\n",
       "            YEN_FU_weekly_percent_change_Nonreportable Positions Short  \\\n",
       "Date                                                                     \n",
       "2006-06-25                                          -0.284957            \n",
       "2006-07-02                                           0.098720            \n",
       "2006-07-09                                          -0.108938            \n",
       "2006-07-16                                          -0.140593            \n",
       "2006-07-23                                           0.322699            \n",
       "\n",
       "            UST_10Y_FU_weekly_percent_change_Open Interest  \\\n",
       "Date                                                         \n",
       "2006-06-25                                        0.096635   \n",
       "2006-07-02                                        0.046394   \n",
       "2006-07-09                                       -0.026388   \n",
       "2006-07-16                                       -0.011381   \n",
       "2006-07-23                                       -0.004893   \n",
       "\n",
       "            YEN_FO_weekly_percent_change_Nonreportable Positions Short  \\\n",
       "Date                                                                     \n",
       "2006-06-25                                          -0.277764            \n",
       "2006-07-02                                           0.084128            \n",
       "2006-07-09                                          -0.095245            \n",
       "2006-07-16                                          -0.142315            \n",
       "2006-07-23                                           0.299812            \n",
       "\n",
       "            UST_10Y_FO_weekly_percent_change_Asset Manager Longs  ...  \\\n",
       "Date                                                              ...   \n",
       "2006-06-25                                           0.186905     ...   \n",
       "2006-07-02                                           0.061635     ...   \n",
       "2006-07-09                                          -0.015988     ...   \n",
       "2006-07-16                                           0.055753     ...   \n",
       "2006-07-23                                           0.004527     ...   \n",
       "\n",
       "            YEN_FO_weekly_percent_change_Nonreportable Positions Long  \\\n",
       "Date                                                                    \n",
       "2006-06-25                                          -0.267675           \n",
       "2006-07-02                                           0.005438           \n",
       "2006-07-09                                           0.014332           \n",
       "2006-07-16                                          -0.019994           \n",
       "2006-07-23                                          -0.053834           \n",
       "\n",
       "            CHF_FO_weekly_percent_change_Open Interest  \\\n",
       "Date                                                     \n",
       "2006-06-25                                   -0.530200   \n",
       "2006-07-02                                    0.104444   \n",
       "2006-07-09                                   -0.072931   \n",
       "2006-07-16                                    0.064258   \n",
       "2006-07-23                                    0.108912   \n",
       "\n",
       "            UST_10Y_FO_weekly_percent_change_Dealer Shorts  \\\n",
       "Date                                                         \n",
       "2006-06-25                                       -0.177814   \n",
       "2006-07-02                                        0.257053   \n",
       "2006-07-09                                       -0.055327   \n",
       "2006-07-16                                        0.135686   \n",
       "2006-07-23                                       -0.228154   \n",
       "\n",
       "            SP500_eMini_FU_weekly_percent_change_Other Reportable Longs  \\\n",
       "Date                                                                      \n",
       "2006-06-25                                           0.646770             \n",
       "2006-07-02                                          -0.058857             \n",
       "2006-07-09                                          -0.203725             \n",
       "2006-07-16                                          -0.288721             \n",
       "2006-07-23                                           0.650258             \n",
       "\n",
       "            PESO_FU_weekly_percent_change_Nonreportable Positions Short  \\\n",
       "Date                                                                      \n",
       "2006-06-25                                          -0.053279             \n",
       "2006-07-02                                           0.125108             \n",
       "2006-07-09                                          -0.130242             \n",
       "2006-07-16                                          -0.316523             \n",
       "2006-07-23                                           0.069903             \n",
       "\n",
       "            CAD_FU_weekly_percent_change_Open Interest  \\\n",
       "Date                                                     \n",
       "2006-06-25                                   -0.048270   \n",
       "2006-07-02                                   -0.272629   \n",
       "2006-07-09                                    0.045105   \n",
       "2006-07-16                                   -0.009196   \n",
       "2006-07-23                                   -0.102852   \n",
       "\n",
       "            WTI_PHYS_FO_weekly_percent_change_Noncommercial Long  \\\n",
       "Date                                                               \n",
       "2006-06-25                                          -0.057170      \n",
       "2006-07-02                                           0.077938      \n",
       "2006-07-09                                           0.074313      \n",
       "2006-07-16                                           0.076219      \n",
       "2006-07-23                                           0.006479      \n",
       "\n",
       "            UST_2Y_FU_weekly_percent_change_Asset Manager Longs  \\\n",
       "Date                                                              \n",
       "2006-06-25                                           0.080200     \n",
       "2006-07-02                                          -0.014777     \n",
       "2006-07-09                                          -0.041798     \n",
       "2006-07-16                                           0.006377     \n",
       "2006-07-23                                           0.013112     \n",
       "\n",
       "            UST_2Y_FU_weekly_percent_change_Dealer Longs  \\\n",
       "Date                                                       \n",
       "2006-06-25                                     -0.000314   \n",
       "2006-07-02                                     -0.007761   \n",
       "2006-07-09                                      0.138786   \n",
       "2006-07-16                                      0.180686   \n",
       "2006-07-23                                      0.145335   \n",
       "\n",
       "            CHF_FO_weekly_percent_change_Nonreportable Positions Long  \n",
       "Date                                                                   \n",
       "2006-06-25                                          -0.185829          \n",
       "2006-07-02                                           0.004747          \n",
       "2006-07-09                                          -0.066220          \n",
       "2006-07-16                                           0.049836          \n",
       "2006-07-23                                          -0.093333          \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[df3.index[:InSamp_length], correlated_variables['Variable']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with low VIF:\n",
      "                                              Variable        VIF\n",
      "47      UST_BOND_FU_weekly_percent_change_Dealer Longs   3.231546\n",
      "139              SOMA_weekly_percent_change_notesbonds   3.419504\n",
      "185   AUD_FO_weekly_percent_change_Noncommercial Short   4.291609\n",
      "21                     SOMA_weekly_percent_change_tips   4.303417\n",
      "0               YIELD_weekly_percent_change_10 YR_lead   4.452752\n",
      "194  PESO_FU_weekly_percent_change_Nonreportable Po...   4.469805\n",
      "184  NATGAS_FO_weekly_percent_change_Nonreportable ...   4.576469\n",
      "193  SP500_eMini_FU_weekly_percent_change_Other Rep...   4.670393\n",
      "197  UST_2Y_FU_weekly_percent_change_Asset Manager ...   4.702151\n",
      "85     UST_BOND_FO_weekly_percent_change_Dealer Shorts   4.715411\n",
      "84   UST_BOND_FU_weekly_percent_change_Other Report...   4.861200\n",
      "18                    SOMA_weekly_percent_change_total   4.977266\n",
      "67     UST_10Y_FU_weekly_percent_change_Dealer Spreads   5.043687\n",
      "198       UST_2Y_FU_weekly_percent_change_Dealer Longs   5.060138\n",
      "86   UST_10Y_FO_weekly_percent_change_Other Reporta...   5.219077\n",
      "179  UST_2Y_FO_weekly_percent_change_Other Reportab...   5.333163\n",
      "190  YEN_FO_weekly_percent_change_Nonreportable Pos...   6.133552\n",
      "109  UST_5Y_FU_weekly_percent_change_Leveraged Fund...   6.277882\n",
      "146  UST_BOND_FU_weekly_percent_change_Leveraged Fu...   6.524760\n",
      "199  CHF_FO_weekly_percent_change_Nonreportable Pos...   6.583388\n",
      "141  UST_5Y_FU_weekly_percent_change_Asset Manager ...   6.644982\n",
      "81    NATGAS_FO_weekly_percent_change_Commercial Short   6.672971\n",
      "10       UST_10Y_FO_weekly_percent_change_Dealer Longs   6.869124\n",
      "30                    YIELD_weekly_percent_change_6 MO   6.910913\n",
      "172   UST_BOND_FO_weekly_percent_change_Dealer Spreads   6.985218\n",
      "150  UST_BOND_FU_weekly_percent_change_Asset Manage...   7.368508\n",
      "144  UST_5Y_FO_weekly_percent_change_Other Reportab...   7.667297\n",
      "71   UST_5Y_FO_weekly_percent_change_Leveraged Fund...   7.880668\n",
      "176  UST_2Y_FO_weekly_percent_change_Leveraged Fund...   7.931110\n",
      "72   SP500_eMini_FO_weekly_percent_change_Other Rep...   8.925464\n",
      "196  WTI_PHYS_FO_weekly_percent_change_Noncommercia...  10.191955\n",
      "137  YEN_FO_weekly_percent_change_Noncommercial Spr...  10.295158\n",
      "80                    YIELD_weekly_percent_change_1 YR  10.603607\n",
      "40   UST_2Y_FU_weekly_percent_change_Leveraged Fund...  10.603806\n",
      "66   UST_10Y_FO_weekly_percent_change_Other Reporta...  10.667549\n",
      "116                   YIELD_weekly_percent_change_3 YR  14.133504\n",
      "167           AUD_FO_weekly_percent_change_Total Short  16.558856\n",
      "103  EURO_FO_weekly_percent_change_Noncommercial Sp...  17.560242\n",
      "45       CHF_FU_weekly_percent_change_Commercial Short  17.574476\n",
      "192     UST_10Y_FO_weekly_percent_change_Dealer Shorts  19.556320\n",
      "48       CHF_FO_weekly_percent_change_Commercial Short  22.547100\n",
      "52      UST_10Y_FU_weekly_percent_change_Dealer Shorts  22.684458\n",
      "44   UST_10Y_FU_weekly_percent_change_Asset Manager...  23.073299\n",
      "57   SP500_eMini_FU_weekly_percent_change_Leveraged...  26.727862\n",
      "152  UST_BOND_FO_weekly_percent_change_Other Report...  27.343454\n",
      "168  UST_BOND_FU_weekly_percent_change_Other Report...  29.196689\n",
      "23   UST_10Y_FO_weekly_percent_change_Asset Manager...  29.665855\n",
      "173  UST_10Y_FU_weekly_percent_change_Leveraged Fun...  33.456946\n",
      "83   UST_10Y_FO_weekly_percent_change_Leveraged Fun...  34.820665\n",
      "53   UST_5Y_FU_weekly_percent_change_Asset Manager ...  39.327544\n",
      "96   WTI_PHYS_FU_weekly_percent_change_Commercial S...  41.532752\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Assuming X is your DataFrame containing the selected variables\n",
    "#vif_results = calculate_vif(df3.iloc[:InSamp_length,[correlated_variables['Variable']]])\n",
    "vif_results = calculate_vif(df3.loc[df3.index[:InSamp_length], correlated_variables['Variable']])\n",
    "\n",
    "# Print the variables with high VIF\n",
    "low_vif_variables = vif_results.sort_values('VIF')[:51]\n",
    "print(\"Variables with low VIF:\")\n",
    "print(low_vif_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
      "C:\\Users\\dstoc\\AppData\\Local\\Temp\\ipykernel_20384\\3338893172.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, make_scorer\n",
    "\n",
    "# Assuming df4 is your DataFrame\n",
    "df6 = df3.copy()\n",
    "df6 = df6[low_vif_variables[\"Variable\"]]\n",
    "# Define your features and target variable\n",
    "features = low_vif_variables[\"Variable\"]\n",
    "features2 = [feature for feature in features if feature != target_var]\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "    for lag in range(1, lag_order+1):\n",
    "        df6[f'{feature}_lag{lag}'] = df6[feature].shift(lag)\n",
    "\n",
    "\n",
    "# replace inf and -inf with na and  drops rows with missing values in the lagged variables\n",
    "df6 = df6[6:]\n",
    "df6 = df6.replace([np.inf, -np.inf], np.nan).dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame X does not contain the target variable: 'YIELD_weekly_percent_change_10 YR_lead'. You may proceed with the back-test.\n"
     ]
    }
   ],
   "source": [
    "df6[target_var] = np.where(df6[target_var] < 0, 'LONG', 'SHORT')\n",
    "X = df6[features2]\n",
    "y = df6[target_var]\n",
    "\n",
    "if target_var.lower() in map(str.lower, X.columns):\n",
    "    print(f\"The DataFrame contains the column '{target_var}'. ABORT BACK-TEST\")\n",
    "else:\n",
    "    print(f\"The DataFrame X does not contain the target variable: '{target_var}'. You may proceed with the back-test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                    \n",
    "                                                                    ## Gridsearch performed below ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 272 folds for each of 2 candidates, totalling 544 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 50, 'subsample': 0.75}\n",
      "Accuracy of the Best Hyperparameters: 0.5294\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid for grid search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 150],\n",
    "#     'learning_rate': [0.01, 0.1],\n",
    "#     'subsample': [0.75],\n",
    "#     'max_depth': [3, 13],\n",
    "#     'min_samples_leaf': [2, 5]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.3],\n",
    "    'subsample': [0.75],\n",
    "    'max_depth': [5,15],\n",
    "    'min_samples_leaf': [5]\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gbm = GradientBoostingClassifier(random_state=248)\n",
    "\n",
    "\n",
    "ys = []\n",
    "\n",
    "def Acc_Score(y_true,y_pred):\n",
    "    global ys\n",
    "    ys.append(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)    \n",
    "    return acc\n",
    "\n",
    "def scorer():\n",
    "    return make_scorer(Acc_Score, greater_is_better=True)\n",
    "\n",
    "# Create the time series split for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=len(df6) - initial_train_size, test_size=1,gap=0, max_train_size=None)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(gbm, param_grid, cv=tscv, scoring=scorer(), verbose=1)#, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_gbm = grid_search.best_estimator_\n",
    "\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f'Accuracy of the Best Hyperparameters: {grid_search.best_score_:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['SHORT'], dtype=object),\n",
       " array(['LONG'], dtype=object),\n",
       " array(['SHORT'], dtype=object)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5294117647058824"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "#Calculate and display accuracy\n",
    "accuracy_score(y[(initial_train_size):], ys[(((len(df6) - initial_train_size) * (grid_search.best_index_))):(len(df6) - initial_train_size) * (grid_search.best_index_ +1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save the model to disk\n",
    "filename = '10Y_UST_gridsearch_results.sav'\n",
    "joblib.dump(grid_search, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estim_preds = ys[(((len(df6) - initial_train_size) * (grid_search.best_index_))):(len(df6) - initial_train_size) * (grid_search.best_index_ +1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estim_preds = np.array(best_estim_preds).flatten().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_estim_preds,'10Y_UST_best_estimator_predictions.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dstoc\\Documents\\Python Scripts\\Fixed Income Dashboards\\GBM Backtest UST_10Y v1.ipynb Cell 27\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dstoc/Documents/Python%20Scripts/Fixed%20Income%20Dashboards/GBM%20Backtest%20UST_10Y%20v1.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estim_preds \u001b[39m=\u001b[39m best_estim_preds\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dstoc/Documents/Python%20Scripts/Fixed%20Income%20Dashboards/GBM%20Backtest%20UST_10Y%20v1.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_model \u001b[39m=\u001b[39m best_gbm\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dstoc/Documents/Python%20Scripts/Fixed%20Income%20Dashboards/GBM%20Backtest%20UST_10Y%20v1.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m backtest_object_10Y_UST_v1 \u001b[39m=\u001b[39m backtest_object(grid_search, X, y, best_estim_preds, best_gbm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dstoc/Documents/Python%20Scripts/Fixed%20Income%20Dashboards/GBM%20Backtest%20UST_10Y%20v1.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(backtest_object_10Y_UST_v1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dstoc/Documents/Python%20Scripts/Fixed%20Income%20Dashboards/GBM%20Backtest%20UST_10Y%20v1.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "class backtest_object:\n",
    "  def __init__(self,grid_search, X, y, best_estim_preds, final_model):\n",
    "    self.grid_search = grid_search\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.best_estim_preds = best_estim_preds\n",
    "    self.final_model = best_gbm\n",
    "\n",
    "backtest_object_10Y_UST_v1 = backtest_object(grid_search, X, y, best_estim_preds, best_gbm)\n",
    "print(backtest_object_10Y_UST_v1)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Serialize the object using pickle and save to a file\n",
    "with open('backtest_object_10Y_UST_v1 .pkl', 'wb') as file:\n",
    "    pickle.dump(backtest_object_10Y_UST_v1, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for predicting off of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.predict(X.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.predict_proba(X.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/modeling-pipeline-optimization-with-scikit-learn/\n",
    "import seaborn as sns \n",
    "sns.relplot(data=cv_results,\n",
    " kind='line',\n",
    " x='param_subsample',\n",
    " y='mean_test_score',\n",
    " hue='param_learning_rate',\n",
    " col='param_max_depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(cv_results['mean_test_score'])\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    " \n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "group1 = cv_results.query('param_learning_rate == 0.3')\n",
    "group2 = cv_results.query('param_learning_rate == 0.1')\n",
    "\n",
    "plt.hist(group1['mean_test_score'], label='LR = 0.3', alpha=0.75)\n",
    "plt.hist(group2['mean_test_score'], label='LR = 0.1', alpha=0.75)\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "group1 = cv_results.query('param_max_depth == 8')\n",
    "group2 = cv_results.query('param_max_depth == 3')\n",
    "\n",
    "plt.hist(group1['mean_test_score'], label='Max Depth = 8', alpha=0.75)\n",
    "plt.hist(group2['mean_test_score'], label='Max Depth = 3', alpha=0.75)\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "group1 = cv_results.query('param_min_samples_leaf == 5')\n",
    "group2 = cv_results.query('param_min_samples_leaf == 1')\n",
    "\n",
    "plt.hist(group1['mean_test_score'], label='Min Samples Leaf = 8', alpha=0.75)\n",
    "plt.hist(group2['mean_test_score'], label='Min Samples Leaf = 1', alpha=0.75)\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "group1 = cv_results.query('param_n_estimators == 50')\n",
    "group2 = cv_results.query('param_n_estimators == 100')\n",
    "\n",
    "plt.hist(group1['mean_test_score'], label='n_estimators = 50', alpha=0.75)\n",
    "plt.hist(group2['mean_test_score'], label='n_estimators = 100', alpha=0.75)\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "group1 = cv_results.query('param_subsample == 1')\n",
    "group2 = cv_results.query('param_subsample == .75')\n",
    "\n",
    "plt.hist(group1['mean_test_score'], label='subsample = 1.0', alpha=0.75)\n",
    "plt.hist(group2['mean_test_score'], label='subsample = 0.75', alpha=0.75)\n",
    "plt.xlabel('% Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of Out-of-Sample Accuracy Scores of Hyperparameter Combos\\n\\n',\n",
    "          fontweight = \"bold\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
